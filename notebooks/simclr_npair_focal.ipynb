{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T15:16:32.463042Z",
          "iopub.status.busy": "2023-07-03T15:16:32.462652Z",
          "iopub.status.idle": "2023-07-03T15:17:33.542468Z",
          "shell.execute_reply": "2023-07-03T15:17:33.541128Z",
          "shell.execute_reply.started": "2023-07-03T15:16:32.463003Z"
        },
        "id": "NoDrzOHO1OPD"
      },
      "outputs": [],
      "source": [
        "!pip install keras-cv\n",
        "!pip install tf-models-official\n",
        "!pip install focal-loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T15:17:33.546864Z",
          "iopub.status.busy": "2023-07-03T15:17:33.546123Z",
          "iopub.status.idle": "2023-07-03T15:17:46.604684Z",
          "shell.execute_reply": "2023-07-03T15:17:46.603665Z",
          "shell.execute_reply.started": "2023-07-03T15:17:33.546832Z"
        },
        "id": "QcXnXzGN1OPJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "from focal_loss import sparse_categorical_focal_loss\n",
        "import keras_cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_recall_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_models as tfm\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T15:17:46.607561Z",
          "iopub.status.busy": "2023-07-03T15:17:46.606608Z",
          "iopub.status.idle": "2023-07-03T15:17:46.640203Z",
          "shell.execute_reply": "2023-07-03T15:17:46.639233Z",
          "shell.execute_reply.started": "2023-07-03T15:17:46.607522Z"
        },
        "id": "-pFcDGXK1OPK"
      },
      "outputs": [],
      "source": [
        "class GeMPooling(keras.layers.Layer):\n",
        "    def __init__(self, p=3, eps=1e-8, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.p = p\n",
        "        self.eps = eps\n",
        "        self.gap = keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "    def call(self, x):\n",
        "        return tf.math.pow(self.gap(tf.math.pow(x + self.eps, self.p)), 1 / self.p)\n",
        "\n",
        "\n",
        "class Contrastive(keras.Model):\n",
        "    def __init__(self, model_dim=256, temperature=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.temperature = temperature\n",
        "\n",
        "        self.feature_extractor = keras.applications.EfficientNetV2B2(include_top=False, weights='imagenet')\n",
        "        self.augmentation = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Rescaling(1 / 255.),\n",
        "                keras.layers.RandomFlip('horizontal'),\n",
        "                keras.layers.Lambda(lambda batch: tf.map_fn(lambda x: tf.image.random_jpeg_quality(x, 50, 100), batch)),\n",
        "                keras.layers.RandomRotation(0.15, fill_mode='constant', fill_value=1.),\n",
        "                keras.layers.RandomTranslation(0.15, 0.15, fill_mode='constant', fill_value=1.),\n",
        "                keras.layers.RandomZoom((-0.3, 0.3), fill_mode='constant', fill_value=1.),\n",
        "                keras.layers.RandomBrightness(0.35, value_range=(0, 1)),\n",
        "                keras_cv.layers.RandomHue(0.35, value_range=(0, 1)),\n",
        "                keras_cv.layers.RandomSharpness(0.35, value_range=(0, 1)),\n",
        "                keras_cv.layers.RandomSaturation((0.35, 0.65)),\n",
        "                keras_cv.layers.RandomCutout(0.4, 0.4, fill_mode='gaussian_noise'),\n",
        "                keras.layers.Lambda(lambda batch: tf.clip_by_value(batch, 0., 1.)),\n",
        "                keras.layers.Rescaling(255.)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.head = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Conv2D(model_dim, kernel_size=1, activation='relu', name='embedding_projection'),\n",
        "                GeMPooling(name='gem_pooling'),\n",
        "                keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1), name='l2_normalization')\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def compile(self, optimizer, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_tracker = keras.metrics.Mean(name='loss')\n",
        "        self.val_loss_tracker = keras.metrics.Mean(name='val_loss')\n",
        "        self.acc_tracker = keras.metrics.Mean(name='acc')\n",
        "        self.val_acc_tracker = keras.metrics.Mean(name='val_loss')\n",
        "\n",
        "    def call(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.head(features)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, _ = data\n",
        "        augmented_1 = self.augmentation(x, training=True)\n",
        "        augmented_2 = self.augmentation(x, training=True)\n",
        "        with tf.GradientTape() as tape:\n",
        "            features_1 = self.feature_extractor(augmented_1)\n",
        "            features_2 = self.feature_extractor(augmented_2)\n",
        "            embeddings_1 = self.head(features_1)\n",
        "            embeddings_2 = self.head(features_2)\n",
        "            loss, acc = self.calculate_loss(embeddings_1, embeddings_2)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.feature_extractor.trainable_weights + self.head.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.feature_extractor.trainable_weights + self.head.trainable_weights))\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.acc_tracker.update_state(acc)\n",
        "        return {'loss': self.loss_tracker.result(), 'acc': self.acc_tracker.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x, _ = data\n",
        "        augmented_1 = self.augmentation(x, training=True)\n",
        "        augmented_2 = self.augmentation(x, training=True)\n",
        "        embeddings_1 = self.call(augmented_1)\n",
        "        embeddings_2 = self.call(augmented_2)\n",
        "        loss, acc = self.calculate_loss(embeddings_1, embeddings_2)\n",
        "        self.val_loss_tracker.update_state(loss)\n",
        "        self.val_acc_tracker.update_state(acc)\n",
        "        return {'loss': self.val_loss_tracker.result(), 'acc': self.val_acc_tracker.result()}\n",
        "\n",
        "    def calculate_loss(self, emb_1, emb_2):\n",
        "        similarities = tf.matmul(emb_1, emb_2, transpose_b=True) / self.temperature\n",
        "        contrastive_labels = tf.range(tf.shape(emb_1)[0])\n",
        "        loss_12 = sparse_categorical_focal_loss(contrastive_labels, similarities, 2, from_logits=True)\n",
        "        loss_21 = sparse_categorical_focal_loss(contrastive_labels, tf.transpose(similarities), 2, from_logits=True)\n",
        "        acc_12 = tf.keras.metrics.sparse_categorical_accuracy(contrastive_labels, similarities)\n",
        "        acc_21 = tf.keras.metrics.sparse_categorical_accuracy(contrastive_labels, tf.transpose(similarities))\n",
        "        return (loss_12 + loss_21) / 2, (acc_12 + acc_21) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T15:17:46.643729Z",
          "iopub.status.busy": "2023-07-03T15:17:46.643300Z",
          "iopub.status.idle": "2023-07-03T15:17:54.257354Z",
          "shell.execute_reply": "2023-07-03T15:17:54.256267Z",
          "shell.execute_reply.started": "2023-07-03T15:17:46.643688Z"
        },
        "id": "79jkOxxm1OPN"
      },
      "outputs": [],
      "source": [
        "def get_connected_components(adjacency_dict):\n",
        "\n",
        "    def dfs(node, component):\n",
        "        visited.add(node)\n",
        "        component.append(node)\n",
        "        neighbors = adjacency_dict.get(node, set())\n",
        "        for neighbor in neighbors:\n",
        "            if neighbor not in visited:\n",
        "                dfs(neighbor, component)\n",
        "\n",
        "    visited = set()\n",
        "    components = []\n",
        "    for node in adjacency:\n",
        "        if node not in visited:\n",
        "            component = []\n",
        "            dfs(node, component)\n",
        "            components.append(component)\n",
        "\n",
        "    return components\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_df['image_name1'] = train_df['image_url1'].apply(lambda x: os.path.basename(x))\n",
        "train_df['image_name2'] = train_df['image_url2'].apply(lambda x: os.path.basename(x))\n",
        "\n",
        "adjacency = {}\n",
        "for ind in train_df.index:\n",
        "    left = train_df.loc[ind, 'image_name1']\n",
        "    right = train_df.loc[ind, 'image_name2']\n",
        "    adjacency.setdefault(left, set()).add(right)\n",
        "    adjacency.setdefault(right, set()).add(left)\n",
        "\n",
        "components = get_connected_components(adjacency)\n",
        "image_labels = {}\n",
        "for i, component in enumerate(components):\n",
        "    for name in component:\n",
        "        image_labels[name] = i\n",
        "\n",
        "print(len(components))\n",
        "\n",
        "keys_tensor = tf.constant(list(image_labels.keys()))\n",
        "vals_tensor = tf.constant(list(image_labels.values()))\n",
        "image_labels_table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), default_value=-1)\n",
        "\n",
        "# for now we will only use one image from each scene\n",
        "selected_images = set([c[0] for c in components])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T15:17:54.259388Z",
          "iopub.status.busy": "2023-07-03T15:17:54.258923Z",
          "iopub.status.idle": "2023-07-03T15:17:57.643486Z",
          "shell.execute_reply": "2023-07-03T15:17:57.642400Z",
          "shell.execute_reply.started": "2023-07-03T15:17:54.259349Z"
        },
        "id": "-NHCGIxG1OPO"
      },
      "outputs": [],
      "source": [
        "HEIGHT, WIDTH = 256, 256\n",
        "BATCH = 512\n",
        "EPOCHS = 50\n",
        "\n",
        "images_list = glob.glob(os.path.join('train', '*'))\n",
        "images_list = [p for p in images_list if os.path.basename(p) in selected_images]\n",
        "\n",
        "n_val_components = 7500\n",
        "train_images = [p for p in images_list if image_labels[os.path.basename(p)] >= n_val_components]\n",
        "val_images = [p for p in images_list if image_labels[os.path.basename(p)] < n_val_components]\n",
        "\n",
        "train_images = train_images + glob.glob('kaggle_room_street_data/*/*jpg') + glob.glob('home_bro/*/*jpg')\n",
        "print(len(train_images), len(val_images))\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_dataset = train_dataset.shuffle(len(train_images), reshuffle_each_iteration=True)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(val_images)\n",
        "val_dataset = val_dataset.shuffle(len(val_images), reshuffle_each_iteration=False)\n",
        "\n",
        "\n",
        "def process_path(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize_with_pad(image, HEIGHT, WIDTH)\n",
        "    label = image_labels_table[tf.strings.split(image_path, os.path.sep)[-1]]\n",
        "    return image, label\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T15:17:57.645626Z",
          "iopub.status.busy": "2023-07-03T15:17:57.645212Z",
          "iopub.status.idle": "2023-07-03T17:36:25.702390Z",
          "shell.execute_reply": "2023-07-03T17:36:25.701305Z",
          "shell.execute_reply.started": "2023-07-03T15:17:57.645590Z"
        },
        "id": "lZp0FMjp1OPP"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.03 * BATCH / 256\n",
        "n_steps = EPOCHS * len(train_dataset)\n",
        "cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(learning_rate, decay_steps=n_steps, alpha=0.05)\n",
        "\n",
        "model = Contrastive()\n",
        "model.compile(optimizer=tfm.optimization.lars_optimizer.LARS(learning_rate=cosine_decay_scheduler))\n",
        "history = model.fit(train_dataset, epochs=20, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j_Tjvnv1OPP"
      },
      "outputs": [],
      "source": [
        "model.compute_output_shape((None, 256, 256, 3))\n",
        "model.save('models/simclr_efficientnetv2b2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T18:00:26.599727Z",
          "iopub.status.busy": "2023-07-03T18:00:26.599342Z",
          "iopub.status.idle": "2023-07-03T18:05:55.850373Z",
          "shell.execute_reply": "2023-07-03T18:05:55.848629Z",
          "shell.execute_reply.started": "2023-07-03T18:00:26.599696Z"
        },
        "id": "65S5fG1V1OPQ"
      },
      "outputs": [],
      "source": [
        "images_list = glob.glob(os.path.join('test', '*'))\n",
        "\n",
        "\n",
        "def process_path_test(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize_with_pad(image, HEIGHT, WIDTH)\n",
        "    label = tf.strings.split(image_path, os.path.sep)[-1]\n",
        "    return image, label\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(images_list)\n",
        "test_dataset = test_dataset.map(process_path_test, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_embeddings = {}\n",
        "for batch in tqdm(test_dataset):\n",
        "    images, names = batch\n",
        "    embeddings = model.call(images)\n",
        "    for name, embedding in zip(names.numpy(), embeddings.numpy()):\n",
        "        test_embeddings[name.decode()] = embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T18:06:05.912693Z",
          "iopub.status.busy": "2023-07-03T18:06:05.912305Z",
          "iopub.status.idle": "2023-07-03T18:06:05.919470Z",
          "shell.execute_reply": "2023-07-03T18:06:05.918258Z",
          "shell.execute_reply.started": "2023-07-03T18:06:05.912663Z"
        },
        "id": "a_MUkoUO1OPR"
      },
      "outputs": [],
      "source": [
        "len(images_list) == len(test_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-03T18:10:39.805765Z",
          "iopub.status.busy": "2023-07-03T18:10:39.805369Z",
          "iopub.status.idle": "2023-07-03T18:10:45.876375Z",
          "shell.execute_reply": "2023-07-03T18:10:45.875222Z",
          "shell.execute_reply.started": "2023-07-03T18:10:39.805733Z"
        },
        "id": "7l6g5B_81OPR"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('test-data.csv')\n",
        "test_df['image_name1'] = test_df['image_url1'].apply(lambda x: os.path.basename(x))\n",
        "test_df['image_name2'] = test_df['image_url2'].apply(lambda x: os.path.basename(x))\n",
        "\n",
        "test_df['simclr'] = 0\n",
        "\n",
        "for ind in tqdm(test_df.index):\n",
        "    image_1 = test_df.loc[ind, 'image_name1']\n",
        "    image_2 = test_df.loc[ind, 'image_name2']\n",
        "\n",
        "    if not (image_1 in test_embeddings.keys() and image_2 in test_embeddings.keys()):\n",
        "        continue\n",
        "\n",
        "    embedding_1 = test_embeddings[image_1]\n",
        "    embedding_2 = test_embeddings[image_2]\n",
        "    test_df.loc[ind, 'simclr'] = np.dot(embedding_1, embedding_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MzwADYU1OPS"
      },
      "outputs": [],
      "source": [
        "test_df.to_csv('test_simclr.csv')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}